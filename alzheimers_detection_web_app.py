"""
é˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ç³»ç»Ÿ - Webå‰ç«¯åº”ç”¨
åŸºäºStreamlitæ„å»ºçš„äº¤äº’å¼Webç•Œé¢
"""

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from pathlib import Path

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ§  é˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ç³»ç»Ÿ (SADS v3.0)</h1>', unsafe_allow_html=True)
st.markdown("---")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # æ•°æ®é›†è·¯å¾„é…ç½®
    st.subheader("ğŸ“ æ•°æ®é›†è·¯å¾„")
    default_path = r"C:\Users\Administrator\Downloads\Datasets-20251115T200020Z-1-001\Datasets"
    dataset_path = st.text_input("æ•°æ®é›†æ ¹ç›®å½•", value=default_path)
    
    # æ•°æ®æºé€‰æ‹©
    st.subheader("ğŸ“Š æ•°æ®æºé€‰æ‹©")
    use_alz_variant = st.checkbox("ä½¿ç”¨ ALZ_Variant æ•°æ®", value=True)
    use_mri = st.checkbox("ä½¿ç”¨ MRI æ•°æ®", value=True)
    combine_datasets = st.checkbox("æ•´åˆæ•°æ®é›†", value=True)
    
    # æ¨¡å‹è®­ç»ƒå‚æ•°
    st.subheader("ğŸ¯ è®­ç»ƒå‚æ•°")
    use_ensemble = st.checkbox("ä½¿ç”¨4æ¨¡å‹é›†æˆï¼ˆæ¨èï¼‰", value=True)
    epochs = st.slider("è®­ç»ƒè½®æ•°", 10, 50, 20)
    batch_size = st.slider("æ‰¹æ¬¡å¤§å°", 8, 32, 16)
    
    # è¿è¡ŒæŒ‰é’®
    st.markdown("---")
    run_analysis = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)
    
    # å…³äºä¿¡æ¯
    st.markdown("---")
    st.markdown("### ğŸ“– å…³äº")
    st.info("""
    æœ¬ç³»ç»Ÿæ•´åˆäº†ï¼š
    - ALZ_Variant é—ä¼ å˜å¼‚æ•°æ®
    - MRI å½±åƒæ•°æ®
    - 4æ¨¡å‹é›†æˆå­¦ä¹ ï¼ˆå¯é€‰ï¼‰
    """)

# ä¸»å†…å®¹åŒºåŸŸ
if run_analysis:
    # æ˜¾ç¤ºè¿›åº¦
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # å¯¼å…¥ä¸»ç¨‹åºæ¨¡å—
        status_text.text("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å—...")
        progress_bar.progress(10)
        
        # è®¾ç½®è·¯å¾„
        BASE_DATASET_PATH = dataset_path
        ALZ_VARIANT_PATH = os.path.join(BASE_DATASET_PATH, "ALZ_Variant")
        MRI_PATH = os.path.join(BASE_DATASET_PATH, "MRI")
        
        # æ•°æ®åŠ è½½éƒ¨åˆ†
        status_text.text("ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†...")
        progress_bar.progress(20)
        
        X_train_final = None
        X_test_final = None
        y_train_final = None
        y_test_final = None
        data_source_info = []
        
        # åŠ è½½ALZ_Variantæ•°æ®
        if use_alz_variant:
            alz_npz_path = os.path.join(ALZ_VARIANT_PATH, "preprocessed_alz_data.npz")
            if os.path.exists(alz_npz_path):
                import numpy as np
                alz_data = np.load(alz_npz_path)
                
                X_train_alz = alz_data['X_train']
                X_test_alz = alz_data['X_test']
                y_train_alz = alz_data['y_train']
                y_test_alz = alz_data['y_test']
                
                # è½¬æ¢ä¸ºäºŒåˆ†ç±»
                if len(y_train_alz.shape) > 1:
                    y_train_alz_binary = (np.argmax(y_train_alz, axis=1) >= 7).astype(int)
                    y_test_alz_binary = (np.argmax(y_test_alz, axis=1) >= 7).astype(int)
                else:
                    y_train_alz_binary = (y_train_alz > 0.5).astype(int)
                    y_test_alz_binary = (y_test_alz > 0.5).astype(int)
                
                X_train_alz_seq = np.stack([X_train_alz, X_train_alz * 0.95], axis=1)
                X_test_alz_seq = np.stack([X_test_alz, X_test_alz * 0.95], axis=1)
                
                X_train_final = X_train_alz_seq
                X_test_final = X_test_alz_seq
                y_train_final = y_train_alz_binary
                y_test_final = y_test_alz_binary
                data_source_info.append("ALZ_Variant")
        
        # åŠ è½½MRIæ•°æ®
        if use_mri and os.path.exists(os.path.join(MRI_PATH, "train.parquet")):
            mri_train = pd.read_parquet(os.path.join(MRI_PATH, "train.parquet"))
            mri_test = pd.read_parquet(os.path.join(MRI_PATH, "test.parquet"))
            
            # å¤„ç†MRIæ•°æ®
            target_col = mri_train.columns[-1]
            feature_cols_mri = [col for col in mri_train.columns if col != target_col]
            
            from sklearn.impute import SimpleImputer
            imputer = SimpleImputer(strategy='mean')
            X_train_mri = imputer.fit_transform(mri_train[feature_cols_mri].values)
            X_test_mri = imputer.transform(mri_test[feature_cols_mri].values)
            
            y_train_mri = mri_train[target_col].values
            y_test_mri = mri_test[target_col].values
            
            if y_train_mri.dtype == object:
                from sklearn.preprocessing import LabelEncoder
                le = LabelEncoder()
                y_train_mri = le.fit_transform(y_train_mri)
                y_test_mri = le.transform(y_test_mri)
            
            if len(np.unique(y_train_mri)) > 2:
                y_train_mri = (y_train_mri == np.max(y_train_mri)).astype(int)
                y_test_mri = (y_test_mri == np.max(y_test_mri)).astype(int)
            
            X_train_mri_seq = np.stack([X_train_mri, X_train_mri * 0.95], axis=1)
            X_test_mri_seq = np.stack([X_test_mri, X_test_mri * 0.95], axis=1)
            
            if combine_datasets and X_train_final is not None:
                min_features = min(X_train_final.shape[2], X_train_mri_seq.shape[2])
                X_train_final = np.concatenate([
                    X_train_final[:, :, :min_features],
                    X_train_mri_seq[:, :, :min_features]
                ], axis=0)
                X_test_final = np.concatenate([
                    X_test_final[:, :, :min_features],
                    X_test_mri_seq[:, :, :min_features]
                ], axis=0)
                y_train_final = np.concatenate([y_train_final, y_train_mri])
                y_test_final = np.concatenate([y_test_final, y_test_mri])
                data_source_info.append("MRI")
            elif X_train_final is None:
                X_train_final = X_train_mri_seq
                X_test_final = X_test_mri_seq
                y_train_final = y_train_mri
                y_test_final = y_test_mri
                data_source_info.append("MRI")
        
        if X_train_final is None:
            st.error("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼è¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„ã€‚")
            st.stop()
        
        status_text.text("ğŸ”§ æ­£åœ¨é¢„å¤„ç†æ•°æ®...")
        progress_bar.progress(40)
        
        # æ•°æ®æ ‡å‡†åŒ–
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_train_2d = X_train_final.reshape(-1, X_train_final.shape[-1])
        X_test_2d = X_test_final.reshape(-1, X_test_final.shape[-1])
        scaler.fit(X_train_2d)
        X_train_scaled = scaler.transform(X_train_2d).reshape(X_train_final.shape)
        X_test_scaled = scaler.transform(X_test_2d).reshape(X_test_final.shape)
        
        # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("è®­ç»ƒæ ·æœ¬æ•°", f"{X_train_final.shape[0]:,}")
        with col2:
            st.metric("æµ‹è¯•æ ·æœ¬æ•°", f"{X_test_final.shape[0]:,}")
        with col3:
            st.metric("ç‰¹å¾ç»´åº¦", X_train_final.shape[2])
        with col4:
            st.metric("æ•°æ®æº", ", ".join(data_source_info))
        
        status_text.text("ğŸ—ï¸ æ­£åœ¨æ„å»ºæ¨¡å‹...")
        progress_bar.progress(50)
        
        import tensorflow as tf
        from tensorflow import keras
        from tensorflow.keras import layers
        
        n_biomarkers = X_train_scaled.shape[2]
        
        if use_ensemble:
            # æ„å»º4æ¨¡å‹é›†æˆ
            def build_lstm_model():
                return keras.Sequential([
                    layers.LSTM(32, activation='relu', return_sequences=True, 
                               input_shape=(2, n_biomarkers)),
                    layers.Dropout(0.3),
                    layers.LSTM(16, activation='relu'),
                    layers.Dense(32, activation='relu'),
                    layers.BatchNormalization(),
                    layers.Dropout(0.3),
                    layers.Dense(16, activation='relu'),
                    layers.Dense(1, activation='sigmoid')
                ])
            
            def build_cnn_model():
                return keras.Sequential([
                    layers.Conv1D(32, kernel_size=1, activation='relu', 
                                 input_shape=(2, n_biomarkers)),
                    layers.MaxPooling1D(pool_size=1),
                    layers.Conv1D(16, kernel_size=1, activation='relu'),
                    layers.Flatten(),
                    layers.Dense(32, activation='relu'),
                    layers.Dropout(0.3),
                    layers.Dense(16, activation='relu'),
                    layers.Dense(1, activation='sigmoid')
                ])
            
            def build_attention_model():
                inputs = keras.Input(shape=(2, n_biomarkers))
                attention = layers.MultiHeadAttention(num_heads=4, key_dim=8)(inputs, inputs)
                attention = layers.Flatten()(attention)
                x = layers.Dense(32, activation='relu')(attention)
                x = layers.BatchNormalization()(x)
                x = layers.Dropout(0.3)(x)
                x = layers.Dense(16, activation='relu')(x)
                outputs = layers.Dense(1, activation='sigmoid')(x)
                return keras.Model(inputs=inputs, outputs=outputs)
            
            def build_hybrid_model():
                inputs = keras.Input(shape=(2, n_biomarkers))
                lstm = layers.LSTM(24, activation='relu', return_sequences=False)(inputs)
                cnn = layers.Conv1D(24, kernel_size=1, activation='relu')(inputs)
                cnn = layers.Flatten()(cnn)
                merged = layers.Concatenate()([lstm, cnn])
                x = layers.Dense(32, activation='relu')(merged)
                x = layers.Dropout(0.3)(x)
                x = layers.Dense(16, activation='relu')(x)
                outputs = layers.Dense(1, activation='sigmoid')(x)
                return keras.Model(inputs=inputs, outputs=outputs)
            
            models = {
                'LSTM': build_lstm_model(),
                'CNN': build_cnn_model(),
                'Attention': build_attention_model(),
                'Hybrid': build_hybrid_model()
            }
            
            for name, model in models.items():
                model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
            
            status_text.text("ğŸ“ æ­£åœ¨è®­ç»ƒ4æ¨¡å‹é›†æˆ...")
            progress_bar.progress(60)
            
            # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
            model_histories = {}
            training_placeholder = st.empty()
            
            for model_name, model in models.items():
                with training_placeholder.container():
                    st.info(f"æ­£åœ¨è®­ç»ƒ {model_name} æ¨¡å‹...")
                history = model.fit(
                    X_train_scaled, y_train_final,
                    validation_split=0.2,
                    epochs=min(epochs, 20),
                    batch_size=batch_size,
                    callbacks=[keras.callbacks.EarlyStopping(
                        monitor='val_loss', patience=5, restore_best_weights=True, verbose=0
                    )],
                    verbose=0
                )
                model_histories[model_name] = history
            
            training_placeholder.empty()
            
            status_text.text("ğŸ“Š æ­£åœ¨è¯„ä¼°é›†æˆæ¨¡å‹...")
            progress_bar.progress(80)
            
            # é›†æˆé¢„æµ‹
            ensemble_preds = []
            for model in models.values():
                pred = model.predict(X_test_scaled, verbose=0).flatten()
                ensemble_preds.append(pred)
            
            y_pred_proba = np.mean(ensemble_preds, axis=0)
            y_pred = (y_pred_proba > 0.5).astype(int)
            history = model_histories['LSTM']
            
        else:
            # å•æ¨¡å‹ç‰ˆæœ¬
            model = keras.Sequential([
                layers.LSTM(32, activation='relu', return_sequences=True, 
                           input_shape=(2, n_biomarkers)),
                layers.Dropout(0.3),
                layers.LSTM(16, activation='relu'),
                layers.Dense(32, activation='relu'),
                layers.BatchNormalization(),
                layers.Dropout(0.3),
                layers.Dense(16, activation='relu'),
                layers.Dense(1, activation='sigmoid')
            ])
            
            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
            
            status_text.text("ğŸ“ æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
            progress_bar.progress(60)
            
            with st.spinner("è®­ç»ƒä¸­ï¼Œè¯·ç¨å€™..."):
                history = model.fit(
                    X_train_scaled, y_train_final,
                    validation_split=0.2,
                    epochs=min(epochs, 20),
                    batch_size=batch_size,
                    verbose=0
                )
            
            status_text.text("ğŸ“Š æ­£åœ¨è¯„ä¼°æ¨¡å‹...")
            progress_bar.progress(80)
            
            y_pred_proba = model.predict(X_test_scaled, verbose=0).flatten()
            y_pred = (y_pred_proba > 0.5).astype(int)
            models = {'Single Model': model}
            ensemble_preds = [y_pred_proba]
        
        from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix
        
        auc = roc_auc_score(y_test_final, y_pred_proba)
        accuracy = accuracy_score(y_test_final, y_pred)
        f1 = f1_score(y_test_final, y_pred)
        cm = confusion_matrix(y_test_final, y_pred)
        
        sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1]) if (cm[1, 0] + cm[1, 1]) > 0 else 0
        specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) > 0 else 0
        
        progress_bar.progress(100)
        status_text.text("âœ… åˆ†æå®Œæˆï¼")
        
        # æ˜¾ç¤ºç»“æœ
        st.markdown("## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("AUC-ROC", f"{auc:.4f}", delta=None)
        with col2:
            st.metric("å‡†ç¡®ç‡", f"{accuracy:.4f}", delta=None)
        with col3:
            st.metric("F1åˆ†æ•°", f"{f1:.4f}", delta=None)
        with col4:
            st.metric("æ•æ„Ÿæ€§", f"{sensitivity:.4f}", delta=None)
        with col5:
            st.metric("ç‰¹å¼‚æ€§", f"{specificity:.4f}", delta=None)
        
        # æ˜¾ç¤ºå•ä¸ªæ¨¡å‹æ€§èƒ½ï¼ˆå¦‚æœæ˜¯é›†æˆï¼‰
        if use_ensemble and len(ensemble_preds) > 1:
            st.markdown("## ğŸ” å•ä¸ªæ¨¡å‹æ€§èƒ½")
            model_aucs = {}
            for model_name, pred in zip(models.keys(), ensemble_preds):
                model_auc = roc_auc_score(y_test_final, pred)
                model_aucs[model_name] = model_auc
            
            model_df = pd.DataFrame({
                'æ¨¡å‹': list(model_aucs.keys()),
                'AUC-ROC': list(model_aucs.values())
            })
            st.dataframe(model_df, use_container_width=True)
        
        # å¯è§†åŒ–
        st.markdown("## ğŸ“Š å¯è§†åŒ–ç»“æœ")
        
        if use_ensemble and len(ensemble_preds) > 1:
            fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        else:
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # ROCæ›²çº¿
        from sklearn.metrics import roc_curve
        fpr, tpr, _ = roc_curve(y_test_final, y_pred_proba)
        axes[0, 0].plot(fpr, tpr, linewidth=2, label=f'AUC={auc:.4f}')
        axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1)
        axes[0, 0].fill_between(fpr, tpr, alpha=0.2)
        axes[0, 0].set_xlabel('å‡é˜³æ€§ç‡')
        axes[0, 0].set_ylabel('çœŸé˜³æ€§ç‡')
        axes[0, 0].set_title('ROCæ›²çº¿')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ··æ·†çŸ©é˜µ
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1], cbar=False, square=True)
        axes[0, 1].set_title('æ··æ·†çŸ©é˜µ')
        axes[0, 1].set_ylabel('çœŸå®å€¼')
        axes[0, 1].set_xlabel('é¢„æµ‹å€¼')
        
        # é¢„æµ‹åˆ†å¸ƒ
        axes[1, 0].hist(y_pred_proba[y_test_final==0], bins=15, alpha=0.6, label='æ­£å¸¸', color='green')
        axes[1, 0].hist(y_pred_proba[y_test_final==1], bins=15, alpha=0.6, label='é˜¿å°”èŒ¨æµ·é»˜ç—…', color='red')
        axes[1, 0].axvline(0.5, color='black', linestyle='--', linewidth=2)
        axes[1, 0].set_xlabel('é¢„æµ‹æ¦‚ç‡')
        axes[1, 0].set_title('é¢„æµ‹åˆ†å¸ƒ')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ€§èƒ½æŒ‡æ ‡æŸ±çŠ¶å›¾
        if use_ensemble and len(ensemble_preds) > 1:
            metrics = ['AUC', 'å‡†ç¡®ç‡', 'F1', 'æ•æ„Ÿæ€§', 'ç‰¹å¼‚æ€§']
            values = [auc, accuracy, f1, sensitivity, specificity]
            colors = ['#4ECDC4' if v > 0.8 else '#FF6B6B' for v in values]
            axes[1, 1].bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
            axes[1, 1].set_ylabel('åˆ†æ•°')
            axes[1, 1].set_title('æ•´ä½“æ€§èƒ½')
            axes[1, 1].set_ylim([0.5, 1.0])
            axes[1, 1].grid(True, alpha=0.3, axis='y')
            
            # æ¨¡å‹æ¯”è¾ƒ
            model_aucs = [roc_auc_score(y_test_final, pred) for pred in ensemble_preds]
            colors_models = ['#4ECDC4' if auc_val == max(model_aucs) else '#FF6B6B' for auc_val in model_aucs]
            axes[1, 2].bar(models.keys(), model_aucs, color=colors_models, alpha=0.7, edgecolor='black')
            axes[1, 2].set_ylabel('AUC-ROC')
            axes[1, 2].set_title('å•ä¸ªæ¨¡å‹æ€§èƒ½')
            axes[1, 2].set_ylim([0.7, 1.0])
            axes[1, 2].grid(True, alpha=0.3, axis='y')
        else:
            metrics = ['AUC', 'å‡†ç¡®ç‡', 'F1', 'æ•æ„Ÿæ€§', 'ç‰¹å¼‚æ€§']
            values = [auc, accuracy, f1, sensitivity, specificity]
            colors = ['#4ECDC4' if v > 0.8 else '#FF6B6B' for v in values]
            axes[1, 1].bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
            axes[1, 1].set_ylabel('åˆ†æ•°')
            axes[1, 1].set_title('æ•´ä½“æ€§èƒ½')
            axes[1, 1].set_ylim([0.5, 1.0])
            axes[1, 1].grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # è®­ç»ƒå†å²
        st.markdown("## ğŸ“‰ è®­ç»ƒå†å²")
        history_df = pd.DataFrame(history.history)
        st.line_chart(history_df[['loss', 'val_loss']])
        
        # ä¸´åºŠé¢„æµ‹ç¤ºä¾‹
        st.markdown("## ğŸ¥ ä¸´åºŠé£é™©è¯„ä¼°ç¤ºä¾‹")
        for i in range(min(5, len(X_test_scaled))):
            prob = y_pred_proba[i]
            if prob > 0.75:
                risk = "ğŸ”´ æé«˜é£é™©"
            elif prob > 0.6:
                risk = "ğŸŸ  é«˜é£é™©"
            elif prob > 0.4:
                risk = "ğŸŸ¡ ä¸­ç­‰é£é™©"
            else:
                risk = "ğŸŸ¢ ä½é£é™©"
            
            st.markdown(f"**æ‚£è€… {i+1}**: é£é™©æ¦‚ç‡ = {prob:.1%} | {risk}")
        
    except Exception as e:
        st.error(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.exception(e)

else:
    # æ¬¢è¿é¡µé¢
    st.markdown("""
    ## ğŸ‘‹ æ¬¢è¿ä½¿ç”¨é˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ç³»ç»Ÿ
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„é˜¿å°”èŒ¨æµ·é»˜ç—…æ—©æœŸæ£€æµ‹ç³»ç»Ÿï¼Œæ•´åˆäº†å¤šç§æ•°æ®æºå’Œå…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
    
    ### âœ¨ ä¸»è¦åŠŸèƒ½
    
    1. **å¤šæ•°æ®æºæ•´åˆ**
       - ALZ_Variant é—ä¼ å˜å¼‚æ•°æ®
       - MRI å½±åƒæ•°æ®
       - è‡ªåŠ¨æ•°æ®é¢„å¤„ç†
    
    2. **é›†æˆå­¦ä¹ æ¨¡å‹**
       - LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰
       - CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰
       - Attentionï¼ˆæ³¨æ„åŠ›æœºåˆ¶ï¼‰
       - Hybridï¼ˆæ··åˆæ¨¡å‹ï¼‰
    
    3. **å…¨é¢æ€§èƒ½è¯„ä¼°**
       - AUC-ROC æ›²çº¿
       - æ··æ·†çŸ©é˜µ
       - å¤šç§è¯„ä¼°æŒ‡æ ‡
    
    4. **ä¸´åºŠé£é™©è¯„ä¼°**
       - æ‚£è€…é£é™©æ¦‚ç‡é¢„æµ‹
       - å¯è§†åŒ–ç»“æœå±•ç¤º
    
    ### ğŸš€ å¿«é€Ÿå¼€å§‹
    
    1. åœ¨å·¦ä¾§è¾¹æ é…ç½®æ•°æ®é›†è·¯å¾„
    2. é€‰æ‹©è¦ä½¿ç”¨çš„æ•°æ®æº
    3. è°ƒæ•´è®­ç»ƒå‚æ•°ï¼ˆå¯é€‰ï¼‰
    4. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
    
    ### ğŸ“Š æ•°æ®é›†è¦æ±‚
    
    - **ALZ_Variant**: `preprocessed_alz_data.npz` æ–‡ä»¶
    - **MRI**: `train.parquet` å’Œ `test.parquet` æ–‡ä»¶
    
    ### âš ï¸ æ³¨æ„äº‹é¡¹
    
    - é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´è¿›è¡Œæ¨¡å‹è®­ç»ƒ
    - å»ºè®®ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹
    - ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—è¯Šæ–­
    """)
    
    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
    st.markdown("### ğŸ“ æ•°æ®é›†ä¿¡æ¯")
    info_col1, info_col2 = st.columns(2)
    
    with info_col1:
        st.markdown("""
        **ALZ_Variant æ•°æ®**
        - æ ¼å¼: NPZ (NumPyå‹ç¼©)
        - è®­ç»ƒé›†: 5076æ ·æœ¬ Ã— 130ç‰¹å¾
        - æµ‹è¯•é›†: 1270æ ·æœ¬ Ã— 130ç‰¹å¾
        - æ ‡ç­¾: 9åˆ†ç±»ï¼ˆå·²è½¬æ¢ä¸ºäºŒåˆ†ç±»ï¼‰
        """)
    
    with info_col2:
        st.markdown("""
        **MRI æ•°æ®**
        - æ ¼å¼: Parquet (åˆ—å¼å­˜å‚¨)
        - åŒ…å«è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        - å½±åƒç›¸å…³ç‰¹å¾æ•°æ®
        - é€‚åˆå¤§æ•°æ®åˆ†æ
        """)

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "é˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ç³»ç»Ÿ (SADS v3.0) | "
    "åŸºäºStreamlitæ„å»º | "
    "Â© 2025"
    "</div>",
    unsafe_allow_html=True
)
